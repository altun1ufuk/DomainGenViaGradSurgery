{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70fd1309",
   "metadata": {},
   "source": [
    "Ufuk Altun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adae3e8",
   "metadata": {},
   "source": [
    "using Pkg; pkg\"add CUDA Knet IterTools FileIO JLD2 Images Plots PyCall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1345dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "@pyimport torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b96f5b1",
   "metadata": {},
   "source": [
    "## Use Pycall to imitate dataloading of the original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb16e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "\n",
    "py\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageFile\n",
    "#import datasets\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_dir', type=str, default=\"/Users/ufukaltun/PycharmProjects/DGVGS/DGvGS-main/data/pre\")\n",
    "parser.add_argument('--dataset', type=str, default='PACS')\n",
    "parser.add_argument('--method', type=str, default='deep-all')\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "parser.add_argument('--iterations', type=int, default=300)\n",
    "parser.add_argument('--val_every', type=int, default=20)\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "parser.add_argument('--lr', type=float, default=1e-5)\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-5)\n",
    "parser.add_argument('--test_dom_idx', type=int, default=1)\n",
    "parser.add_argument('--output_dir', type=str, default=\"result/train\")\n",
    "args = parser.parse_args()\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "def get_domains(dataset_name):\n",
    "    return globals()[dataset_name].DOMAINS\n",
    "\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, file_path, image_dir, transform=None):\n",
    "        self.file_path = file_path\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self._read_file()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = os.path.join(self.image_dir, self.image_paths[idx])\n",
    "\n",
    "        with open(path, 'rb') as f:\n",
    "            image = Image.open(f).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _read_file(self):\n",
    "        with open(self.file_path) as f:\n",
    "            for line in f:\n",
    "                path, label = line.strip().split(',')\n",
    "                self.image_paths.append(path)\n",
    "                self.labels.append(int(label) - 1)\n",
    "\n",
    "class MultiDomainDataset:\n",
    "\n",
    "    def __init__(self, root_dir, test_dom_idx):\n",
    "        images_dir = os.path.join(root_dir, 'images')\n",
    "        split_dir = os.path.join(root_dir, 'split')\n",
    "\n",
    "        domains = [f.name for f in os.scandir(images_dir) if f.is_dir()]\n",
    "        domains.sort()\n",
    "\n",
    "        test_dom = domains[test_dom_idx]\n",
    "        train_doms = [d for d in domains if d != test_dom]\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "        train_datasets, val_datasets = [], []\n",
    "        for dom_name in train_doms:\n",
    "            train_datasets.append(ImageDataset(\n",
    "                os.path.join(split_dir, dom_name + '_train.txt'),\n",
    "                images_dir,\n",
    "                transform))\n",
    "            val_datasets.append(ImageDataset(\n",
    "                os.path.join(split_dir, dom_name + '_val.txt'),\n",
    "                images_dir,\n",
    "                transform))\n",
    "\n",
    "        self.datasets = {}\n",
    "        self.datasets['train'] = train_datasets\n",
    "        self.datasets['val'] = torch.utils.data.ConcatDataset(val_datasets)\n",
    "        self.datasets['test'] = ImageDataset(\n",
    "            os.path.join(split_dir, test_dom + '_test.txt'),\n",
    "            images_dir,\n",
    "            transform)\n",
    "\n",
    "    def __getitem__(self, phase):\n",
    "        if phase in ['train', 'val', 'test']:\n",
    "            return self.datasets[phase]\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "\n",
    "class VLCS(MultiDomainDataset):\n",
    "\n",
    "    N_CLASSES = 5\n",
    "    DOMAINS = ['C', 'L', 'S', 'V']\n",
    "\n",
    "    def __init__(self, root_dir, test_dom_idx):\n",
    "        self.root_dir = os.path.join(root_dir, 'VLCS/')\n",
    "        super().__init__(self.root_dir, test_dom_idx)\n",
    "\n",
    "\n",
    "class PACS(MultiDomainDataset):\n",
    "\n",
    "    N_CLASSES = 7\n",
    "    DOMAINS = ['A', 'C', 'P', 'S']\n",
    "\n",
    "    def __init__(self, root_dir, test_dom_idx):\n",
    "        self.root_dir = os.path.join(root_dir, 'PACS/')\n",
    "        super().__init__(self.root_dir, test_dom_idx)\n",
    "\n",
    "############# data loader ###########\n",
    "\n",
    "class InfiniteDataLoader(torch.utils.data.DataLoader):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dataset_iterator = super().__iter__()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            batch = next(self.dataset_iterator)\n",
    "        except StopIteration:\n",
    "            self.dataset_iterator = super().__iter__()\n",
    "            batch = next(self.dataset_iterator)\n",
    "        return batch\n",
    "\n",
    "dataset = PACS(args.data_dir, args.test_dom_idx)\n",
    "\n",
    "\n",
    "############# Model ##########\n",
    "\n",
    "def get_model(device, dataset, args):\n",
    "    if args.method == 'deep-all':\n",
    "        return ModelDA(device, dataset, args)\n",
    "    elif args.method in ['agr-sum', 'agr-rand', 'pcgrad']:\n",
    "        return ModelGS(device, dataset, args)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "class ModelDA:\n",
    "\n",
    "    def __init__(self, device, dataset, args):\n",
    "        self.device = device\n",
    "        self.args = args\n",
    "        self._create_dataloaders(dataset, args)\n",
    "\n",
    "    def _create_dataloaders(self, dataset, args):\n",
    "\n",
    "        def get_dataloader(dataset, batch_size, is_train=False):\n",
    "            if is_train:\n",
    "                return InfiniteDataLoader(\n",
    "                    dataset=dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True)\n",
    "            else:\n",
    "                return torch.utils.data.DataLoader(\n",
    "                    dataset=dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=False,\n",
    "                    drop_last=False)\n",
    "\n",
    "        self.train_loaders = []\n",
    "        for dom_dataset in dataset['train']:\n",
    "            self.train_loaders.append(get_dataloader(dom_dataset, args.batch_size, True))\n",
    "        self.val_loader = get_dataloader(dataset['val'], args.batch_size)\n",
    "        self.test_loader = get_dataloader(dataset['test'], args.batch_size)\n",
    "\n",
    "    def _prepare_batch(self, batch):\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.to(self.device)\n",
    "        targets = targets.to(self.device)\n",
    "        return inputs, targets\n",
    "\n",
    "    def train(self):\n",
    "        train_iterator = zip(*self.train_loaders)\n",
    "        val_iterator = self.val_loader\n",
    "        test_iterator = self.test_loader\n",
    "        \n",
    "        iterations = self.args.iterations\n",
    "        val_every = self.args.val_every\n",
    "\n",
    "        return train_iterator, val_iterator, test_iterator\n",
    "        #for it in range(iterations):\n",
    "        # Training\n",
    "        #    train_batches = [self._prepare_batch(batch) for batch in next(train_iterator)]\n",
    "        #    train_loss, train_acc = self._train_step(train_batches)\n",
    "        #    is_train = True\n",
    "        #    inputs = torch.cat([x for x, _ in train_batches])\n",
    "        #    targets = torch.cat([y for _, y in train_batches])\n",
    "\n",
    "\n",
    "\n",
    "###################\n",
    "\n",
    "#dataset = vars(datasets)[args.dataset](args.data_dir, args.test_dom_idx)\n",
    "#dataset = PACS(args.data_dir, args.test_dom_idx)\n",
    "model = ModelDA(device, dataset, args)\n",
    "train_iterator, val_iterator, test_iterator = model.train()\n",
    "\n",
    "def prep_batch(batch):\n",
    "    inputs, targets = batch\n",
    "    inputs = inputs.to('cpu')\n",
    "    targets = targets.to('cpu')\n",
    "    return inputs, targets\n",
    "    \n",
    "\n",
    "############## def return data #######\n",
    "def return_data(train_iterator):\n",
    "    train_batches = [prep_batch(batch) for batch in next(train_iterator)]\n",
    "    inputs = torch.cat([x for x, _ in train_batches])\n",
    "    targets = torch.cat([y for _, y in train_batches])\n",
    "    return inputs, targets\n",
    "\n",
    "def return_val_data(val_iterator):\n",
    "    train_batches = [prep_batch(batch) for batch in val_iterator]\n",
    "    inputs = torch.cat([x for x, _ in train_batches])\n",
    "    targets = torch.cat([y for _, y in train_batches])\n",
    "    return inputs, targets\n",
    "    \n",
    "def return_data_gs(train_iterator):\n",
    "    train_batches = [prep_batch(batch) for batch in next(train_iterator)]\n",
    "    return train_batches\n",
    "    \n",
    "\"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1c2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"models.jl\");\n",
    "include(\"training.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127b255",
   "metadata": {},
   "source": [
    "#### Generate an alexnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4454bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = generate_alexnet_model( 7 ; pretrained = true);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e952ad86",
   "metadata": {},
   "source": [
    "#### Set optimizers of each parameter to Adam. Parameter sizes should be:\n",
    "##### Original Alexnet\n",
    "- (11, 11, 3, 64)\n",
    "- (1, 1, 64, 1)\n",
    "- (5, 5, 64, 192)\n",
    "- (1, 1, 192, 1)\n",
    "- (3, 3, 192, 384)\n",
    "- (1, 1, 384, 1)\n",
    "- (3, 3, 384, 256)\n",
    "- (1, 1, 256, 1)\n",
    "- (3, 3, 256, 256)\n",
    "- (1, 1, 256, 1)\n",
    "- (4096, 9216)\n",
    "- (4096,)\n",
    "- (4096, 4096)\n",
    "- (4096,)\n",
    "- (7, 4096)\n",
    "- (7,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065ef923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11, 3, 64)\n",
      "(1, 1, 64, 1)\n",
      "(5, 5, 64, 192)\n",
      "(1, 1, 192, 1)\n",
      "(3, 3, 192, 384)\n",
      "(1, 1, 384, 1)\n",
      "(3, 3, 384, 256)\n",
      "(1, 1, 256, 1)\n",
      "(3, 3, 256, 256)\n",
      "(1, 1, 256, 1)\n",
      "(4096, 9216)\n",
      "(4096,)\n",
      "(4096, 4096)\n",
      "(4096,)\n",
      "(7, 4096)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "for param in params(model)\n",
    "    param.opt = Adam(; lr=1e-5)\n",
    "    println(size(param))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d439ef",
   "metadata": {},
   "source": [
    "#### Define batchsize, model path and target domain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2953cd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cartoon\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_iter=600\n",
    "check_freq=20\n",
    "batchsize = 128\n",
    "atype = Array{Float32}\n",
    "data_path = \"/Users/ufukaltun/Documents/koç/dersler/ku deep learning/project/data\";\n",
    "target = \"cartoon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8009e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_val, targets_val = py\"return_val_data(val_iterator)\"\n",
    "inputs_val = permutedims(inputs_val.detach().numpy(), (4, 3, 2, 1));\n",
    "targets_val = targets_val.detach().numpy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d317cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, targets_test = py\"return_val_data(test_iterator)\"\n",
    "inputs_test = permutedims(inputs_test.detach().numpy(), (4, 3, 2, 1));\n",
    "targets_test = targets_test.detach().numpy();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171d0e46",
   "metadata": {},
   "source": [
    "## Training of Baseline model with \"Cartoon\" target, PACS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c09bd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "┣                    ┫ [0.17%, 1/600, 00:00/00:01, 995.64i/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch is trained successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣▋                   ┫ [3.33%, 20/600, 12:01/06:00:43, 34.64s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.4085758"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "┣▋                   ┫ [3.50%, 21/600, 13:51/06:35:45, 109.64s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val loss: 1.5214493  Train acc: 0.5214723926380368  Val acc: 0.44849445324881143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣█▎                  ┫ [6.83%, 41/600, 27:07/06:36:43, 100.03s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0361052  Val loss: 1.1410123  Train acc: 0.6276923076923077  Val acc: 0.5832012678288431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██                  ┫ [10.17%, 61/600, 40:22/06:37:01, 101.38s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6770923  Val loss: 0.90846246  Train acc: 0.7694805194805194  Val acc: 0.6576862123613312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██▋                 ┫ [13.50%, 81/600, 53:52/06:39:03, 108.77s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.63129944  Val loss: 0.74905396  Train acc: 0.7641509433962265  Val acc: 0.7337559429477021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣███▎                ┫ [16.83%, 101/600, 01:07:18/06:39:46, 102.69s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5136729  Val loss: 0.64311653  Train acc: 0.8170347003154574  Val acc: 0.7638668779714739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████                ┫ [20.17%, 121/600, 01:20:56/06:41:20, 101.50s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.37836137  Val loss: 0.56522363  Train acc: 0.8475609756097561  Val acc: 0.7892234548335975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████▋               ┫ [23.50%, 141/600, 01:34:33/06:42:18, 100.09s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30146593  Val loss: 0.51837486  Train acc: 0.8987341772151899  Val acc: 0.8066561014263075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣█████▎              ┫ [26.83%, 161/600, 01:48:25/06:44:02, 103.13s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.31053635  Val loss: 0.48111856  Train acc: 0.8885448916408669  Val acc: 0.8256735340729001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████              ┫ [30.17%, 181/600, 02:01:33/06:42:55, 103.84s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.20385881  Val loss: 0.45375693  Train acc: 0.9341692789968652  Val acc: 0.8367670364500792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████▋             ┫ [33.50%, 201/600, 02:14:38/06:41:54, 101.26s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2125772  Val loss: 0.42791003  Train acc: 0.9327217125382263  Val acc: 0.8431061806656102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣███████▎            ┫ [36.83%, 221/600, 02:27:35/06:40:42, 99.63s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.16916327  Val loss: 0.4108  Train acc: 0.9569230769230769  Val acc: 0.8573692551505546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████            ┫ [40.17%, 241/600, 02:40:36/06:39:50, 100.73s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.13714819  Val loss: 0.39227238  Train acc: 0.9501557632398754  Val acc: 0.8557844690966719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████▋           ┫ [43.50%, 261/600, 02:53:41/06:39:16, 102.41s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.11283547  Val loss: 0.381017  Train acc: 0.9622641509433962  Val acc: 0.8652931854199684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣█████████▎          ┫ [46.83%, 281/600, 03:06:48/06:38:52, 100.00s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.11470907  Val loss: 0.37611946  Train acc: 0.9551282051282052  Val acc: 0.8652931854199684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████          ┫ [50.17%, 301/600, 03:20:20/06:39:21, 102.44s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.088965766  Val loss: 0.3620223  Train acc: 0.9747634069400631  Val acc: 0.8716323296354992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████▋         ┫ [53.50%, 321/600, 03:33:27/06:38:58, 103.21s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.08686784  Val loss: 0.36093095  Train acc: 0.9693251533742331  Val acc: 0.8763866877971473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣███████████▎        ┫ [56.83%, 341/600, 03:46:35/06:38:41, 102.60s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05186857  Val loss: 0.34806526  Train acc: 0.99079754601227  Val acc: 0.884310618066561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████        ┫ [60.17%, 361/600, 03:59:45/06:38:29, 101.11s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.044794194  Val loss: 0.3440363  Train acc: 0.9876543209876543  Val acc: 0.884310618066561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████▋       ┫ [63.50%, 381/600, 04:13:04/06:38:31, 103.99s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.055252444  Val loss: 0.34776396  Train acc: 0.9819277108433735  Val acc: 0.8874801901743264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣█████████████▎      ┫ [66.83%, 401/600, 04:26:23/06:38:34, 100.44s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.07424606  Val loss: 0.3427334  Train acc: 0.9782608695652174  Val acc: 0.8858954041204438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████████      ┫ [70.17%, 421/600, 04:39:23/06:38:11, 98.63s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.036103826  Val loss: 0.3453525  Train acc: 0.9936507936507937  Val acc: 0.884310618066561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████████▋     ┫ [73.50%, 441/600, 04:52:23/06:37:48, 100.31s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.028682392  Val loss: 0.3345934  Train acc: 0.9938461538461538  Val acc: 0.8827258320126783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣███████████████▎    ┫ [76.83%, 461/600, 05:05:30/06:37:37, 100.20s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.034097034  Val loss: 0.35122663  Train acc: 0.9935275080906149  Val acc: 0.8858954041204438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████████    ┫ [80.17%, 481/600, 05:18:38/06:37:27, 102.54s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.033544566  Val loss: 0.33292723  Train acc: 0.9807692307692307  Val acc: 0.8922345483359746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████████▋   ┫ [83.50%, 501/600, 05:31:46/06:37:19, 100.75s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.024951257  Val loss: 0.33240846  Train acc: 1.0  Val acc: 0.8922345483359746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣█████████████████▎  ┫ [86.83%, 521/600, 05:44:53/06:37:10, 97.50s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.016679421  Val loss: 0.33732545  Train acc: 1.0  Val acc: 0.8922345483359746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████████████  ┫ [90.17%, 541/600, 05:57:50/06:36:52, 98.13s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010127131  Val loss: 0.33860353  Train acc: 1.0  Val acc: 0.8890649762282092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████████████▋ ┫ [93.50%, 561/600, 06:10:54/06:36:41, 99.37s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.007621357  Val loss: 0.34247118  Train acc: 1.0  Val acc: 0.8922345483359746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣███████████████████▎┫ [96.83%, 581/600, 06:23:57/06:36:31, 101.88s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.012343519  Val loss: 0.33897206  Train acc: 1.0  Val acc: 0.8969889064976229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████████████┫ [100.00%, 600/600, 06:35:24/06:35:24, 35.26s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.013096458  Val loss: 0.34188887  Train acc: 1.0  Val acc: 0.8858954041204438\n",
      "Training ended successfully, saving the results\n",
      "Test loss: 1.3054203  Test acc: 0.6675191815856778\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "results=[]\n",
    "best_acc=-1\n",
    "for it in progress(1:num_iter)\n",
    "    inputs_train, targets_train = py\"return_data(train_iterator)\"\n",
    "    inputs_train = permutedims(inputs_train.detach().numpy(), (4, 3, 2, 1));\n",
    "    targets_train = targets_train.detach().numpy();\n",
    "\n",
    "    D = @diff model(inputs_train, targets_train);\n",
    "    for w in Knet.params(model)\n",
    "        g = grad(D, w)\n",
    "        update!(w, g)\n",
    "    end\n",
    "    if n==1 \n",
    "        println(\"First batch is trained successfully\")\n",
    "        best_acc = accuracy(model(inputs_val),targets_val)\n",
    "    end\n",
    "    if n%check_freq == 0\n",
    "        acc = accuracy(model(inputs_val),targets_val)\n",
    "        if acc > best_acc\n",
    "            best_acc = acc\n",
    "            save(string(\"best_model_b_debugging_target_\", target,\".jld2\"),\"weights\",model)\n",
    "        end\n",
    "        result=(model(inputs_train, targets_train), model(inputs_val, targets_val), \n",
    "                    accuracy(model(inputs_train),targets_train), acc)\n",
    "        println(\"Train loss: \",result[1],\"  Val loss: \",result[2],\n",
    "                \"  Train acc: \",result[3],\"  Val acc: \",result[4])\n",
    "        push!(results,result)\n",
    "    end\n",
    "\n",
    "    (n += 1) > num_iter && break\n",
    "end \n",
    "println(\"Training ended successfully, saving the results\")\n",
    "save(string(\"results_b_debugging_target_\", target,\".jld2\"),\"results\",results)\n",
    "best_model = load(string(\"best_model_b_debugging_target_\", target,\".jld2\"))[\"weights\"]\n",
    "tst_loss = best_model(inputs_test, targets_test)\n",
    "tst_acc = accuracy(model(inputs_test),targets_test)\n",
    "println(\"Test loss: \", tst_loss, \"  Test acc: \", tst_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0222e56",
   "metadata": {},
   "source": [
    "## Training of Gradient Surgery model with \"Cartoon\" target, PACS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ba58451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "┣                    ┫ [0.17%, 1/600, 00:00/00:00, 1839.36i/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch is trained successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣▋                   ┫ [3.33%, 20/600, 11:48/05:53:52, 34.37s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1176128"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "┣▋                   ┫ [3.50%, 21/600, 13:27/06:24:26, 99.56s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val loss: 2.133992  Train acc: 0.27100328645546606  Val acc: 0.2583201267828843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣█▎                  ┫ [6.83%, 41/600, 26:51/06:32:49, 105.07s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6800386  Val loss: 1.6481905  Train acc: 0.38772794200928756  Val acc: 0.3692551505546751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██                  ┫ [10.17%, 61/600, 39:48/06:31:33, 100.15s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2505255  Val loss: 1.3738507  Train acc: 0.5027629233511587  Val acc: 0.48019017432646594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██▋                 ┫ [13.50%, 81/600, 53:06/06:33:19, 101.87s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.1999702  Val loss: 1.1759523  Train acc: 0.5623292075907362  Val acc: 0.561014263074485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣███▎                ┫ [16.83%, 101/600, 01:06:25/06:34:31, 103.42s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0379937  Val loss: 1.0238854  Train acc: 0.6066872238271833  Val acc: 0.6212361331220285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████                ┫ [20.17%, 121/600, 01:19:54/06:36:13, 101.19s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7890194  Val loss: 0.90811145  Train acc: 0.7098022228526012  Val acc: 0.6719492868462758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████▋               ┫ [23.50%, 141/600, 01:32:54/06:35:17, 99.73s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.67838126  Val loss: 0.8182379  Train acc: 0.737755381873029  Val acc: 0.7068145800316957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣█████▎              ┫ [26.83%, 161/600, 01:45:52/06:34:32, 100.04s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.70036966  Val loss: 0.74389416  Train acc: 0.7660866910866911  Val acc: 0.7194928684627575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████              ┫ [30.17%, 181/600, 01:59:10/06:35:03, 101.89s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5425684  Val loss: 0.6851195  Train acc: 0.8052278637838145  Val acc: 0.7527733755942948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████▋             ┫ [33.50%, 201/600, 02:12:04/06:34:14, 101.11s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5990903  Val loss: 0.6419718  Train acc: 0.8150118299747083  Val acc: 0.7702060221870047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣███████▎            ┫ [36.83%, 221/600, 02:25:04/06:33:50, 100.55s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.48171905  Val loss: 0.6102722  Train acc: 0.8274124345194087  Val acc: 0.7765451664025357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████            ┫ [40.17%, 241/600, 02:38:31/06:34:40, 101.14s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.44776157  Val loss: 0.5823609  Train acc: 0.824278226141942  Val acc: 0.7812995245641838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████▋           ┫ [43.50%, 261/600, 02:51:36/06:34:29, 101.69s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.43215403  Val loss: 0.55676997  Train acc: 0.8546257364090057  Val acc: 0.7812995245641838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣█████████▎          ┫ [46.83%, 281/600, 03:04:40/06:34:18, 102.96s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4051808  Val loss: 0.5389829  Train acc: 0.8652681992337165  Val acc: 0.7955625990491284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████          ┫ [50.17%, 301/600, 03:17:52/06:34:25, 103.77s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.339008  Val loss: 0.51649094  Train acc: 0.8786737142000299  Val acc: 0.8050713153724247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████▋         ┫ [53.50%, 321/600, 03:31:00/06:34:23, 100.28s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.34300157  Val loss: 0.49576774  Train acc: 0.8796899437622708  Val acc: 0.8193343898573693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣███████████▎        ┫ [56.83%, 341/600, 03:43:55/06:34:00, 100.45s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25773257  Val loss: 0.4840932  Train acc: 0.9156308892367054  Val acc: 0.8225039619651348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████        ┫ [60.17%, 361/600, 03:56:59/06:33:53, 101.92s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.24254006  Val loss: 0.47028902  Train acc: 0.9227599524374734  Val acc: 0.8256735340729001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████▋       ┫ [63.50%, 381/600, 04:10:10/06:33:58, 101.46s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28257778  Val loss: 0.45632926  Train acc: 0.8959134501258129  Val acc: 0.8367670364500792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣█████████████▎      ┫ [66.83%, 401/600, 04:23:30/06:34:17, 99.54s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2923469  Val loss: 0.44868937  Train acc: 0.9116621682411156  Val acc: 0.838351822503962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████████      ┫ [70.17%, 421/600, 04:36:42/06:34:20, 103.94s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28189528  Val loss: 0.4471563  Train acc: 0.8982232716396107  Val acc: 0.8335974643423137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████████▋     ┫ [73.50%, 441/600, 04:49:51/06:34:21, 100.21s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.21448715  Val loss: 0.4292802  Train acc: 0.9372210876635655  Val acc: 0.8462757527733756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣███████████████▎    ┫ [76.83%, 461/600, 05:03:03/06:34:26, 102.85s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.20756511  Val loss: 0.42194444  Train acc: 0.9267087349467212  Val acc: 0.8510301109350238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████████    ┫ [80.17%, 481/600, 05:16:10/06:34:23, 101.48s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2550551  Val loss: 0.41701376  Train acc: 0.9049863716530383  Val acc: 0.8462757527733756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████████▋   ┫ [83.50%, 501/600, 05:29:13/06:34:17, 102.45s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.18725419  Val loss: 0.40954953  Train acc: 0.9320718901666325  Val acc: 0.8605388272583201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣█████████████████▎  ┫ [86.83%, 521/600, 05:42:26/06:34:22, 98.70s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.19949584  Val loss: 0.4026128  Train acc: 0.9410641449562281  Val acc: 0.8605388272583201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████████████  ┫ [90.17%, 541/600, 05:55:41/06:34:29, 101.55s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1554196  Val loss: 0.39998448  Train acc: 0.9493226898887276  Val acc: 0.8621236133122029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████████████▋ ┫ [93.50%, 561/600, 06:08:48/06:34:26, 102.57s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.14438382  Val loss: 0.3924485  Train acc: 0.9553701015965167  Val acc: 0.8652931854199684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣███████████████████▎┫ [96.83%, 581/600, 06:21:50/06:34:19, 97.60s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.12688617  Val loss: 0.3879612  Train acc: 0.9469829598506069  Val acc: 0.8621236133122029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████████████┫ [100.00%, 600/600, 06:33:24/06:33:24, 37.68s/i] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.12101819  Val loss: 0.38308683  Train acc: 0.9436403289558629  Val acc: 0.8763866877971473\n",
      "Training ended successfully, saving the results\n",
      "Test loss: 1.0162643  Test acc: 0.7135549872122762\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "results=[]\n",
    "best_acc=0\n",
    "for it in progress(1:num_iter)\n",
    "    train_batches = py\"return_data_gs(train_iterator)\"\n",
    "    inputs1, targets1 = train_batches[1];\n",
    "    inputs1 = permutedims(inputs1.detach().numpy(), (4, 3, 2, 1));\n",
    "    targets1 = targets1.detach().numpy();\n",
    "    \n",
    "    inputs2, targets2 = train_batches[2];\n",
    "    inputs2 = permutedims(inputs2.detach().numpy(), (4, 3, 2, 1));\n",
    "    targets2 = targets2.detach().numpy();\n",
    "    \n",
    "    inputs3, targets3 = train_batches[3];\n",
    "    inputs3 = permutedims(inputs3.detach().numpy(), (4, 3, 2, 1));\n",
    "    targets3 = targets3.detach().numpy();\n",
    "    \n",
    "    D1 = @diff model(inputs1, targets1)\n",
    "    D2 = @diff model(inputs2, targets2)\n",
    "    D3 = @diff model(inputs3, targets3)\n",
    "\n",
    "    for w in Knet.params(model)\n",
    "        g1 = grad(D1, w)\n",
    "        g2 = grad(D2, w)\n",
    "        g3 = grad(D3, w)\n",
    "        MaskGS = abs.(sign.(g1).+sign.(g2).+sign.(g3)).==3\n",
    "        g = (g1.+g2.+g3).*MaskGS\n",
    "        update!(w, g)\n",
    "    end\n",
    "\n",
    "    if n==1 \n",
    "        println(\"First batch is trained successfully\")\n",
    "        best_acc = accuracy(model(inputs_val),targets_val)\n",
    "    end\n",
    "\n",
    "    if n%check_freq == 0\n",
    "        acc = accuracy(model(inputs_val),targets_val)\n",
    "        if acc > best_acc\n",
    "            best_acc = acc\n",
    "            save(string(\"best_model_gs_debugging_target_\", target,\".jld2\"),\"weights\",model)\n",
    "        end\n",
    "        temp_loss = (model(inputs1, targets1) + model(inputs2, targets2) + model(inputs3, targets3))/3\n",
    "        temp_acc = (accuracy(model(inputs1),targets1) + accuracy(model(inputs2),targets2) + accuracy(model(inputs3),targets3))/3\n",
    "        result=(temp_loss, model(inputs_val, targets_val), temp_acc, acc)\n",
    "        println(\"Train loss: \",result[1],\"  Val loss: \",result[2],\n",
    "                \"  Train acc: \",result[3],\"  Val acc: \",result[4])\n",
    "        push!(results,result)\n",
    "    end\n",
    "\n",
    "    (n += 1) > num_iter && break\n",
    "end \n",
    "println(\"Training ended successfully, saving the results\")\n",
    "save(string(\"results_gs_debugging_target_\", target,\".jld2\"),\"results\",results)\n",
    "best_model = load(string(\"best_model_gs_debugging_target_\", target,\".jld2\"))[\"weights\"]\n",
    "tst_loss = best_model(inputs_test, targets_test)\n",
    "tst_acc = accuracy(model(inputs_test),targets_test)\n",
    "println(\"Test loss: \", tst_loss, \"  Test acc: \", tst_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d41f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.4",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
