{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Julia_Colab_Notebook_Template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Julia",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ1r1bbb0yBv"
      },
      "source": [
        "# <img src=\"https://github.com/JuliaLang/julia-logo-graphics/raw/master/images/julia-logo-color.png\" height=\"100\" /> _Colab Notebook Template_\n",
        "\n",
        "## Instructions\n",
        "1. Work on a copy of this notebook: _File_ > _Save a copy in Drive_ (you will need a Google account). Alternatively, you can download the notebook using _File_ > _Download .ipynb_, then upload it to [Colab](https://colab.research.google.com/).\n",
        "2. If you need a GPU: _Runtime_ > _Change runtime type_ > _Harware accelerator_ = _GPU_.\n",
        "3. Execute the following cell (click on it and press Ctrl+Enter) to install Julia, IJulia and other packages (if needed, update `JULIA_VERSION` and the other parameters). This takes a couple of minutes.\n",
        "4. Reload this page (press Ctrl+R, or ⌘+R, or the F5 key) and continue to the next section.\n",
        "\n",
        "_Notes_:\n",
        "* If your Colab Runtime gets reset (e.g., due to inactivity), repeat steps 2, 3 and 4.\n",
        "* After installation, if you want to change the Julia version or activate/deactivate the GPU, you will need to reset the Runtime: _Runtime_ > _Factory reset runtime_ and repeat steps 3 and 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIeFXS0F0zww",
        "outputId": "cd09ad1a-3ee4-422f-ac1a-1a6cdf391ff5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.6.0\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia BenchmarkTools Plots Knet ArgParse\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\n",
        "JULIA_NUM_THREADS=2\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -n \"$COLAB_GPU\" ] && [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  if [ \"$COLAB_GPU\" = \"1\" ]; then\n",
        "      JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia  \n",
        "\n",
        "  echo ''\n",
        "  echo \"Success! Please reload this page and jump to the next section.\"\n",
        "fi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Julia 1.6.0 on the current Colab Runtime...\n",
            "2021-11-13 17:17:01 URL:https://storage.googleapis.com/julialang2/bin/linux/x64/1.6/julia-1.6.0-linux-x86_64.tar.gz [112838927/112838927] -> \"/tmp/julia.tar.gz\" [1]\n",
            "Installing Julia package IJulia...\n",
            "Installing Julia package BenchmarkTools...\n",
            "Installing Julia package Plots...\n",
            "Installing Julia package Knet...\n",
            "Installing Julia package ArgParse...\n",
            "Installing Julia package CUDA...\n",
            "Installing IJulia kernel...\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mInstalling julia kernelspec in /root/.local/share/jupyter/kernels/julia-1.6\n",
            "\n",
            "Success! Please reload this page and jump to the next section.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OS3Ac017T1i"
      },
      "source": [
        "# Checking the Installation\n",
        "The `versioninfo()` function should print your Julia version and some other info about the system:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEzvvzCl1i0F",
        "outputId": "5c80777d-2d9c-41b1-b8fb-b47a7ad79820",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "versioninfo()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Julia Version 1.6.0\n",
            "Commit f9720dc2eb (2021-03-24 12:55 UTC)\n",
            "Platform Info:\n",
            "  OS: Linux (x86_64-pc-linux-gnu)\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "  WORD_SIZE: 64\n",
            "  LIBM: libopenlibm\n",
            "  LLVM: libLLVM-11.0.1 (ORCJIT, haswell)\n",
            "Environment:\n",
            "  JULIA_NUM_THREADS = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQlpeR9wNOi8",
        "outputId": "77803066-8331-4582-ec71-7b604846ad52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "using BenchmarkTools\n",
        "\n",
        "M = rand(2048, 2048)\n",
        "@benchmark M^2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 10 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m489.243 ms\u001b[22m\u001b[39m … \u001b[35m604.164 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.22% … 19.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m502.942 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.11%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m514.367 ms\u001b[22m\u001b[39m ± \u001b[32m 34.846 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m2.78% ±  5.96%\n",
              "\n",
              "  \u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m█\u001b[34m▁\u001b[39m\u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \n",
              "  \u001b[39m█\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[32m▁\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m \u001b[39m▁\n",
              "  489 ms\u001b[90m           Histogram: frequency by time\u001b[39m          604 ms \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m32.00 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m2\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XciCcMAJOT3_",
        "outputId": "00bb4d68-86fd-4321-e2ff-b3dbbf8d009b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if ENV[\"COLAB_GPU\"] == \"1\"\n",
        "    using CUDA\n",
        "\n",
        "    M_gpu = cu(M)\n",
        "    @benchmark CUDA.@sync M_gpu^2\n",
        "else\n",
        "    println(\"No GPU found.\")\n",
        "end"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m Downloading\u001b[22m\u001b[39m artifact: CUDA_compat\n",
            "\u001b[32m\u001b[1m Downloading\u001b[22m\u001b[39m artifact: CUDA\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 692 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m5.942 ms\u001b[22m\u001b[39m … \u001b[35m 10.082 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m7.112 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m7.216 ms\u001b[22m\u001b[39m ± \u001b[32m366.690 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
              "\n",
              "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▆\u001b[39m█\u001b[34m▆\u001b[39m\u001b[39m▃\u001b[39m▁\u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[39m█\u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▅\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▅\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m▁\u001b[39m█\u001b[39m▅\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m▁\u001b[39m▄\u001b[39m▆\u001b[39m█\u001b[39m▄\u001b[39m▁\u001b[39m▄\u001b[39m▄\u001b[39m▆\u001b[39m \u001b[39m▇\n",
              "  5.94 ms\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      8.16 ms \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m208 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m8\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHHeqxQGVxQR"
      },
      "source": [
        "Named-entity recognition (NER) (also known as entity identification, entity chunking and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.\n",
        "\n",
        "Most research on NER systems has been structured as taking an unannotated block of text, such as the following **example**:\n",
        "\n",
        "**INPUT:** Jim bought 300 shares of Acme Corp. in 2006.\n",
        "\n",
        "And producing an annotated block of text that highlights the names of entities:\n",
        "\n",
        "**OUTPUT:** [Jim]Person bought 300 shares of [Acme Corp.]Organization in [2006]Time.\n",
        "\n",
        "In this example, a person name consisting of one token, a two-token company name and a temporal expression have been detected and classified.(Wikipedia)\n",
        "\n",
        "Your task in this lab is to implement named entity LSTM based tagger which uses an LSTM to extract features from the input sentence, which are then passed through a multi-layer perceptron to predict\n",
        "the tag of the word. Finally, train that model on [WikiNER](https://github.com/neulab/dynet-benchmark/tree/master/data/tags) dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXfAqGAJXCvl",
        "outputId": "d8573778-6d5b-47f7-aa4a-35691b0b5de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import Pkg; Pkg.add(\"IterTools\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.6/Project.toml`\n",
            " \u001b[90m [c8e1da08] \u001b[39m\u001b[92m+ IterTools v1.3.0\u001b[39m\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLpcFX1zVyuk",
        "outputId": "67a4a309-1f5b-46c1-a4a2-0ad300683b40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "using Printf, Dates, Random, CUDA, Knet, ArgParse, Test, Base.Iterators, IterTools\n",
        "\n",
        "STDOUT = Base.stdout\n",
        "\n",
        "import Knet: train!\n",
        "include(joinpath(Knet.dir(), \"data\", \"wikiner.jl\"))\n",
        "_atype = CUDA.functional() ? KnetArray{Float32} : Array{Float32}\n",
        "\n",
        "@info \"Adding required packages and importing WikiNER dataset\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "┌ Info: Adding required packages and importing WikiNER dataset\n",
            "└ @ Main In[10]:9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LxPgypHV4kj"
      },
      "source": [
        "## Prepare samples for the network\n",
        "Your first task is to prepare instances for the network. We're given with the tokens (words and tags) and we need to make them understandable by our neural network. For this purpose, we build vocabularies (for both words and tags) and construct vocabulary to index dictionaries by using those vocabularies (w2i and t2i, word2index, tag2index). Then, we convert words and tags to indices with the usage of our dictionaries.\n",
        "\n",
        "```julia\n",
        "julia> show_instance() # show instance in not implemented in Knet, it is a hypothetical procedure\n",
        "Inputs sentence:\n",
        "Sent-> That inscribed in the genealogical records of his family is Jiang Zhoutai .\n",
        "NERs-> O    O         O  O   O            O       O  O   O      O  I-PER I-PER   O\n",
        "\n",
        "Timesteps:\n",
        "Time step 1 ---> Inputs: That\n",
        "                 Outputs: O\n",
        "Time step 2 ---> Inputs: inscribed\n",
        "                 Outputs:O\n",
        "Time step 3 ---> Inputs: in\n",
        "                 Outputs: O\n",
        "Time step 4 ---> Inputs: the\n",
        "                 Outputs: O\n",
        "Time step 5 ---> Inputs: genealogical\n",
        "                 Outputs: O\n",
        "Time step 6 ---> Inputs: records  .\n",
        "                 Outputs: O\n",
        "Time step 7 ---> Inputs: of\n",
        "                 Outputs: O\n",
        "Time step 8 ---> Inputs: his\n",
        "                 Outputs: O\n",
        "Time step 9 ---> Inputs: family\n",
        "                 Outputs: O\n",
        "Time step 10 --->Inputs: is\n",
        "                 Outputs: O\n",
        "Time step 11 ---> Inputs: Jiang\n",
        "                  Outputs: I-PER\n",
        "Time step 12 ---> Inputs: Zhoutai\n",
        "                  Outputs: I-PER\n",
        "Time step 13 ---> Inputs: .\n",
        "                  Outputs: O\n",
        "```\n",
        "\n",
        "Our input and output arrays should be integers instead of texts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZnF4HqIV__g"
      },
      "source": [
        "In this step, you need to implement `make_instance` function\n",
        "instance is a list of tuples. Each tuple contains a word and the corresponding tag as string.\n",
        "You need to convert them into indices using word to index (w2i) and tag to index (t2i)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaZxe2nWWAlP",
        "outputId": "bc0a2783-efb7-432e-fba7-809cac9e4453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "    make_instance(instance, w2i, t2i)\n",
        "\n",
        "Return tuple of two sequences containing inputs and the corresponding outputs respectively.\n",
        "\n",
        "This function does this by converting each input unit in the instance into its corresponding value in w2i, and does the same for output units using t2i.\n",
        "\"\"\"\n",
        "function make_instance(instance, w2i, t2i, unk=UNK)\n",
        "    input = Array{Int}([])\n",
        "    output = Array{Int}([])\n",
        "    # Your code here\n",
        "    for l = 1:length(instance)\n",
        "        push!(input, get!(w2i, instance[l][1], 17516))\n",
        "        push!(output, get!(t2i, instance[l][2], 6))\n",
        "    end\n",
        "    return input, output\n",
        "end\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "   make_instances(data, w2i, t2i)\n",
        "\n",
        "Iterate over `data` and Return `words` and `tags`\n",
        "\"\"\"\n",
        "function make_instances(data, w2i, t2i)\n",
        "    words = []; tags = []\n",
        "    for k = 1:length(data)\n",
        "        this_words, this_tags = make_instance(data[k], w2i, t2i)\n",
        "        push!(words, this_words)\n",
        "        push!(tags, this_tags)\n",
        "    end\n",
        "    return words, tags\n",
        "end\n",
        "\n",
        "@info \"Testing instances\"\n",
        "data = WikiNERData();\n",
        "dev = make_instances(data.dev, data.w2i, data.t2i);\n",
        "@test dev[1][2][3] == 22450\n",
        "@test size.(dev) == ((1696,), (1696,))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "┌ Info: Testing instances\n",
            "└ @ Main In[49]:35\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKbu-WODWLq8"
      },
      "source": [
        "### WikiNERProcessed\n",
        "This struct contains processed data (e.g words and tags are indices)\n",
        "and necessary variables to prepare minibatches.\n",
        "WikiNERProcessed struct works as a data iterator, which will you implement in the next step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO-_0VpEWECk",
        "outputId": "42a41fae-183f-4e08-f59e-4f93a4fa9fe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mutable struct WikiNERProcessed\n",
        "    words\n",
        "    tags\n",
        "    batchsize\n",
        "    ninstances\n",
        "    shuffled\n",
        "end\n",
        "\n",
        "\"\"\"\n",
        "   WikiNERProcessed(instances, w2i, t2i; batchsize=16, shuffled=true)\n",
        "\n",
        "Return a WikiNERProcessed object with the given instances\n",
        "\"\"\"\n",
        "function WikiNERProcessed(instances, w2i, t2i; batchsize=16, shuffled=true)\n",
        "    words, tags = make_instances(instances, w2i, t2i)\n",
        "    ninstances = length(words)\n",
        "    return WikiNERProcessed(words, tags, batchsize, ninstances, shuffled)\n",
        "end\n",
        "\n",
        "@info \"WikiNERProcessed\"\n",
        "devdata = WikiNERProcessed(data.dev, data.w2i, data.t2i; shuffled=false);\n",
        "@test devdata.words[1][1] == 17516\n",
        "@test length(devdata.words) == 1696"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "┌ Info: WikiNERProcessed\n",
            "└ @ Main In[50]:20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNd7q_2dWS-O"
      },
      "source": [
        "### WikiNERProcessed Iterator\n",
        "Please note that this function returns tuple of two tuples.\n",
        "\n",
        "The first one contains a data batch with words as an input for our model, and tags as the corresponding output, and batchsizes of this batch.\n",
        "Since you will use the RNN callable object in your model.\n",
        "It supports variable length instances in its input.\n",
        "However, you need to prepare your input such as the RNN object can work on it. See `batchSizes` option of the RNN object using `@doc RNN` and Look up `zeros`, `sortperm`, `min`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWzs4d5CWaUl",
        "outputId": "0f783f82-1e7e-46ac-daeb-319e58a55e4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "    iterate(d::WikiNERProcessed[, state])\n",
        "\n",
        "Iterate over `d::WikiNERProcessed` object. If `state` is missing, it's the beginning\n",
        "of the whole iteration process. \n",
        "WikiNERProcessed(words, tags, batchsize, ninstances, shuffled)\n",
        "\n",
        "for each batch:\n",
        "    define input_array\n",
        "    sort sequences by their length (longer first)\n",
        "    for each timestep_i in longest sample\n",
        "        for each sequence s in ordered_sequences\n",
        "             add unit_i of sequence s to our input array\n",
        "\n",
        "\"\"\"\n",
        "function Base.iterate(d::WikiNERProcessed, state=ifelse(d.shuffled, randperm(d.ninstances), 1:d.ninstances))\n",
        "    # Your code here\n",
        "    println(size(state))\n",
        "    this_words= d.words[state]\n",
        "    this_tags= d.tags[state]\n",
        "    words = Array{Int}([]); tags = Array{Int}([])\n",
        "    if size(state,1)<d.batchsize\n",
        "        these_words = this_words[1:end]\n",
        "        these_tags =  this_tags[1:end]\n",
        "        \n",
        "        these_lengths = length.(these_words)\n",
        "        these_lengths_sorted = sortperm(these_lengths,rev=true)\n",
        "        \n",
        "        those_words = these_words[sortperm(these_lengths,rev=true)]\n",
        "        those_tags = these_tags[sortperm(these_lengths,rev=true)]\n",
        "        those_lengths = length.(those_words)\n",
        "        \n",
        "        println(those_lengths[1])                \n",
        "        for m in 1:those_lengths[1]\n",
        "            for n in 1:size(state,1)\n",
        "                try\n",
        "                    push!(words, those_words[n][m])\n",
        "                    push!(tags, those_tags[n][m])\n",
        "                catch\n",
        "                end\n",
        "            end\n",
        "        end\n",
        "    else\n",
        "        these_words = this_words[1:d.batchsize]\n",
        "        these_tags =  this_tags[1:d.batchsize]\n",
        "        println(length(these_words))\n",
        "        these_lengths = length.(these_words)\n",
        "        these_lengths_sorted = sortperm(these_lengths,rev=true)\n",
        "\n",
        "        \n",
        "        those_words = these_words[these_lengths_sorted]\n",
        "        those_tags = these_tags[these_lengths_sorted]\n",
        "        those_lengths = length.(those_words)\n",
        "\n",
        "        batchsizes = Array{Int}(zeros(those_lengths[1]))\n",
        "        #println(those_lengths)                    \n",
        "        for m in 1:those_lengths[1]\n",
        "            for n in 1:d.batchsize\n",
        "                try\n",
        "                    push!(words, those_words[n][m])\n",
        "                    batchsizes[m] = batchsizes[m] + 1\n",
        "                   # println(n)\n",
        "                   # println(m)\n",
        "                   # println(those_words[n][m])  \n",
        "                    push!(tags, those_tags[n][m])\n",
        "                catch\n",
        "                end     \n",
        "            end\n",
        "        end\n",
        "    #println(Int.(batchsizes)) Array{Int}([])\n",
        "    @show typeof(batchsizes)    \n",
        "    end\n",
        "    state = state[d.batchsize+1:end]\n",
        "    #batchsizes = zeros(1,those_lengths[1])\n",
        "    if state == []\n",
        "        return nothing\n",
        "    end\n",
        "    \n",
        "    return ((words, tags, batchsizes), state)\n",
        "end\n",
        "\n",
        "Base.IteratorSize(::Type{WikiNERProcessed}) = Base.SizeUnknown()\n",
        "Base.IteratorEltype(::Type{WikiNERProcessed}) = Base.HasEltype()\n",
        "\n",
        "@info \"Testing WikiNERProcessed Iterator\"\n",
        "((words, tags, batchsizes), new_state) = iterate(devdata);\n",
        "\n",
        "@test length.((words, tags, batchsizes)) == (397, 397, 55)\n",
        "@test new_state == 17:1696"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "┌ Info: Testing WikiNERProcessed Iterator\n",
            "└ @ Main In[94]:85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1696,)\n",
            "16\n",
            "typeof(batchsizes) = Vector{Int64}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvGmjdz1WhZu"
      },
      "source": [
        "## Model Components implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z10BDnjHWj7p"
      },
      "source": [
        "### Embedding layer\n",
        "This layer maps each vocabulary to its corresponding vector using its Int id. It works with mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C88drjGWnbn",
        "outputId": "4042de43-bc61-4c42-d1f7-a1dfc6f7e8f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "    Embedding(vocabsize::Int, embedsize::Int, atype=_atype, scale=0.01)\n",
        "\n",
        "Create a Embedding layer and initialize its weight. Initial weight parameters are\n",
        "sampled from normal distribution scaled by a `scale` factor.\n",
        "\n",
        "# Examples\n",
        "```julia-repl\n",
        "julia> embed = Embedding(100, 25);\n",
        "\n",
        "julia> x = rand(1:10, 10);\n",
        "\n",
        "julia> embed(x); # forward call\n",
        "```\n",
        "\"\"\"\n",
        "mutable struct Embedding\n",
        "    w # weight\n",
        "end\n",
        "\n",
        "function Embedding(vocabsize::Int, embedsize::Int, atype=_atype, scale=0.01)\n",
        "    w = Param(convert(atype, scale*randn(embedsize, vocabsize)));\n",
        "    return Embedding(w)\n",
        "end\n",
        "\n",
        "\n",
        "function (l::Embedding)(x)\n",
        "    l.w[:, x]\n",
        "end\n",
        "\n",
        "\n",
        "\n",
        "@info \"Testing embedding layer\"\n",
        "Random.seed!(1)\n",
        "embed = Embedding(100, 25);\n",
        "x = rand(1:25, 12, 32);\n",
        "@test size(embed(x)) == (25, 12, 32)\n",
        "@test sum(embed(x)) ≈ -5.08327f0"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "┌ Info: Testing embedding layer\n",
            "└ @ Main In[95]:32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_5OBXHwWpwU"
      },
      "source": [
        "### Linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BszqzmvLWrdd",
        "outputId": "feb1c564-3202-4944-fcdb-95680e21180d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "    Linear(inputsize, outputsize; atype=Array{Float64}, scale::Float64=0.1)\n",
        "\n",
        "Create a linear layer with its weight and bias. Initial weight parameters are\n",
        "sampled from normal distribution scaled by a `scale` factor. Initial bias\n",
        "values are zeros.\n",
        "\n",
        "# Examples\n",
        "```julia-repl\n",
        "julia> layer = Linear(50, 10);\n",
        "\n",
        "julia> x = rand(2, 50);\n",
        "\n",
        "julia> layer(x); # forward call\n",
        "```\n",
        "\n",
        "struct Linear; w; b; end\n",
        "\n",
        "Linear(input::Int, output::Int)=Linear(param(output,input), param0(output))\n",
        "\n",
        "(l::Linear)(x) = l.w * mat(x,dims=1) .+ l.b  # (H,B,T)->(H,B*T)->(V,B*T)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "mutable struct Linear\n",
        "    w # weight\n",
        "    b # bias\n",
        "\n",
        "    function Linear(inputsize, outputsize; atype=_atype, scale::Float64=0.01)\n",
        "        # Your code here\n",
        "        w = Param(convert(atype,scale*randn(outputsize,inputsize)))\n",
        "        #w = Param(scale*randn(outputsize,inputsize))\n",
        "        b = Param(convert(atype,zeros(outputsize,1)))\n",
        "        new(w,b)\n",
        "    end\n",
        "end\n",
        "\n",
        "function (l::Linear)(x)\n",
        "    # Your code here\n",
        "    l.w * mat(x,dims=1) .+ l.b  # (H,B,T)->(H,B*T)->(V,B*T)\n",
        "end\n",
        "\n",
        "\n",
        "\n",
        "@info \"Testing linear layer\"\n",
        "Random.seed!(1)\n",
        "lin = Linear(100, 200);\n",
        "x = _atype(randn(100, 32));\n",
        "@test size(lin(x)) == (200, 32)\n",
        "@test sum(lin(x)) ≈ -3.8317218f0"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "┌ Info: Testing linear layer\n",
            "└ @ Main In[79]:45\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmXFtKmIWtkk"
      },
      "source": [
        "### Hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5rqYJUVWv2c",
        "outputId": "81b502d1-b815-4343-8ed7-78b489fb9e62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "    Hidden(inputsize, outputsize, fun=relu, atype=_atype, scale=0.1)\n",
        "\n",
        "Create a hidden layer with its weight and bias and activation function. Initial weight parameters are\n",
        "sampled from normal distribution scaled by a `scale` factor. Initial bias\n",
        "values are zeros.\n",
        "\n",
        "# Examples\n",
        "```julia-repl\n",
        "julia> layer = Hidden(100, 200);\n",
        "\n",
        "julia> x = rand(100, 5);\n",
        "\n",
        "julia> layer(x); # forward call\n",
        "```\n",
        "\"\"\"\n",
        "mutable struct Hidden\n",
        "    w # weight\n",
        "    b # bias\n",
        "    fun # non-linear activation function like relu or tanh\n",
        "\n",
        "    function Hidden(inputsize, outputsize, fun=relu, atype=_atype, scale=0.1)\n",
        "        # Your code here\n",
        "        w = Param(convert(atype,scale*randn(outputsize,inputsize)))\n",
        "        b = Param(convert(atype,zeros(outputsize,1)))\n",
        "        fun = relu\n",
        "        new(w,b,relu)\n",
        "    end\n",
        "end\n",
        "\n",
        "function (l::Hidden)(x)\n",
        "    # Your code here\n",
        "    max.(0,(l.w * mat(x,dims=1) .+ l.b))  # (H,B,T)->(H,B*T)->(V,B*T)\n",
        "    #relu(l.w * mat(x,dims=1) .+ l.b)\n",
        "end\n",
        "\n",
        "@info \"Testing hidden layer\"\n",
        "Random.seed!(1)\n",
        "hid = Hidden(200, 256);\n",
        "x = _atype(randn(200, 32));\n",
        "println(size(hid(x)))\n",
        "@test size(hid(x)) == (256, 32)\n",
        "@test sum(hid(x)) ≈ 4635.545f0"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "┌ Info: Testing hidden layer\n",
            "└ @ Main In[80]:37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKxpwJRFWzxN"
      },
      "source": [
        "### NER Tagger model\n",
        "\n",
        "Our model consists of four layers. Size of their outputs are as the following:\n",
        "* **(T)** - Input\n",
        "* **(E, T)** - Embedding\n",
        "* **(RNN, T)** - RNN\n",
        "* **(H, T)** - Hidden\n",
        "* **(NTags, T)** - Projection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5ZPsjJkgqsP"
      },
      "source": [
        "    #m.embed(m.rnn(m.hidden(m.projection(x)));batchsizes)\n",
        "    a = m.embed(x)\n",
        "    @show size(x,1)\n",
        "    @show size(a)\n",
        "    b = m.rnn(a)\n",
        "    @show size(b)\n",
        "    c = m.hidden(b)\n",
        "    @show size(c)\n",
        "    d = m.projection(c)\n",
        "    @show size(d)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8Xv-7vdW34P",
        "outputId": "d96f6a4c-e373-4afe-9c62-5eea3c57f9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "\n",
        "mutable struct NERTagger\n",
        "    embed::Embedding\n",
        "    rnn::RNN\n",
        "    hidden::Hidden\n",
        "    projection::Linear\n",
        "end\n",
        "\n",
        "function NERTagger(no_words, no_tags, embed_size, rnn_hidden_size, mlp_hidden_size, atype=_atype)\n",
        "    # Your code here\n",
        "    embed = Embedding(no_words, embed_size)\n",
        "    rnn = RNN(embed_size, rnn_hidden_size,atype=_atype)\n",
        "    hidden = Hidden(rnn_hidden_size, mlp_hidden_size)\n",
        "    projection = Linear(mlp_hidden_size, no_tags,atype=_atype)\n",
        "\n",
        "    return NERTagger(embed, rnn, hidden, projection)\n",
        "end\n",
        "\n",
        "function (m::NERTagger)(x; batchsizes=nothing)\n",
        "    # Your code here\n",
        "    m.projection(m.hidden(m.rnn(m.embed(x);batchSizes=batchsizes)))\n",
        "end\n",
        "\n",
        "@info \"Testing forward pass of NERTagger\"\n",
        "Random.seed!(1)\n",
        "nwords, ntags = length(data.w2i), data.ntags\n",
        "model = NERTagger(nwords, ntags, 128, 50, 32)\n",
        "output = model(words; batchsizes=batchsizes)\n",
        "\n",
        "@test size(output) == (9, 397)\n",
        "@test sum(output) == 0.4713313f0"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[98]:31\u001b[22m\n",
            "  Expression: sum(output) == 0.4713313f0\n",
            "   Evaluated: 0.25421953f0 == 0.4713313f0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "┌ Info: Testing forward pass of NERTagger\n",
            "└ @ Main In[98]:24\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LoadError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[91mThere was an error during testing\u001b[39m",
            "",
            "Stacktrace:",
            " [1] record(ts::Test.FallbackTestSet, t::Union{Test.Error, Test.Fail})",
            "   @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:772",
            " [2] do_test(result::Test.ExecutionResult, orig_expr::Any)",
            "   @ Test /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:555",
            " [3] top-level scope",
            "   @ In[98]:31",
            " [4] eval",
            "   @ ./boot.jl:360 [inlined]",
            " [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
            "   @ Base ./loading.jl:1094"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v18_FFcWX-1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5Hwsb96WSDY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UMidUQB03vJ"
      },
      "source": [
        "Add new code cells by clicking the `+ Code` button (or _Insert_ > _Code cell_).\n",
        "\n",
        "Have fun!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/JuliaLang/julia-logo-graphics/master/images/julia-logo-mask.png\" height=\"100\" />"
      ]
    }
  ]
}